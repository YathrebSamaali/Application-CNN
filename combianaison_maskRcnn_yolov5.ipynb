{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YathrebSamaali/Application-CNN/blob/main/combianaison_maskRcnn_yolov5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKRSVmDENNPf",
        "outputId": "b1698ff5-7037-4f77-c4cd-9c6426142e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/274.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Cloning into 'detectron2'...\n",
            "remote: Enumerating objects: 15943, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 15943 (delta 5), reused 4 (delta 4), pack-reused 15930 (from 3)\u001b[K\n",
            "Receiving objects: 100% (15943/15943), 6.70 MiB | 10.37 MiB/s, done.\n",
            "Resolving deltas: 100% (11337/11337), done.\n",
            "Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Collecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black\n",
            "  Downloading black-25.12.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (86 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.4/86.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (25.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from yacs>=0.1.8) (6.0.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.4)\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf<2.4,>=2.1) (4.9.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from black) (8.3.1)\n",
            "Collecting mypy-extensions>=0.4.3 (from black)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.12/dist-packages (from black) (4.5.1)\n",
            "Collecting pytokens>=0.3.0 (from black)\n",
            "  Downloading pytokens-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading black-25.12.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pytokens-0.3.0-py3-none-any.whl (12 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=cca978beecb4dee221ce343a63f7ff28e3ebb249913036975d0f7faf3ba8588b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
            "Successfully built fvcore\n",
            "Installing collected packages: yacs, pytokens, portalocker, pathspec, mypy-extensions, iopath, hydra-core, black, fvcore\n",
            "Successfully installed black-25.12.0 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.1.0 pathspec-0.12.1 portalocker-3.2.0 pytokens-0.3.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATo1hCFENbsK",
        "outputId": "43381588-cda3-434d-cd73-c4569961fa62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17760, done.\u001b[K\n",
            "remote: Counting objects: 100% (121/121), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 17760 (delta 74), reused 39 (delta 39), pack-reused 17639 (from 4)\u001b[K\n",
            "Receiving objects: 100% (17760/17760), 17.15 MiB | 19.17 MiB/s, done.\n",
            "Resolving deltas: 100% (12056/12056), done.\n",
            "/content/yolov5\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhDMtABdCaMS",
        "outputId": "fb385c58-c375-41b3-f657-aa71483b3334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.1.45)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (1.16.3)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.24.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Collecting ultralytics>=8.2.64 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.3.240-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 42)) (25.0)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (75.2.0)\n",
            "Requirement already satisfied: urllib3>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 51)) (2.5.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.5.0)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics>=8.2.64->-r requirements.txt (line 18))\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.3)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading ultralytics-8.3.240-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.3.240 ultralytics-thop-2.0.18\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m128.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -r requirements.txt\n",
        "%pip install -q roboflow\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image , clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zIKzeqJfNhkZ"
      },
      "outputs": [],
      "source": [
        "os.environ[\"DATASET_DIRECTORY\"]=\"/content/datasets\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8YQh2HBNhmk",
        "outputId": "e0163a0a-f917-4239-ed97-6e4241bfa558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.12/dist-packages (1.2.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.11.12)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Requirement already satisfied: pi-heif<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.61.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in /content/datasets/Fish_Species-1 to yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 175847/175847 [00:02<00:00, 62168.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to /content/datasets/Fish_Species-1 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8438/8438 [00:01<00:00, 7721.22it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"N0c8fvEkj4BOP2UGVqdB\")\n",
        "project = rf.workspace(\"test-gm8yy\").project(\"fish_species-sh4x2\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DKvqXKcNhqJ",
        "outputId": "9f23189d-455a-4952-e279-d9d5990542f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "2025-12-17 22:15:53.418319: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766009753.450459     642 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766009753.459907     642 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766009753.483670     642 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766009753.483706     642 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766009753.483714     642 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766009753.483721     642 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=, data=/content/datasets/Fish_Species-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-450-g781b9d57 Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 32.5MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l.pt to yolov5l.pt...\n",
            "100% 89.3M/89.3M [00:00<00:00, 136MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     53850  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model summary: 368 layers, 46159834 parameters, 46159834 gradients, 108.3 GFLOPs\n",
            "\n",
            "Transferred 607/613 items from yolov5l.pt\n",
            "/content/yolov5/models/common.py:898: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "/content/yolov5/models/common.py:898: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n",
            "size\n",
            "  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/Fish_Species-1/train/labels... 3576 images, 15 backgrounds, 0 corrupt: 100% 3576/3576 [00:03<00:00, 1078.97it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/Fish_Species-1/train/images/300-31-_jpg.rf.7ecee172af199b0ecaba06d62474fe62.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/datasets/Fish_Species-1/train/images/300-31-_jpg.rf.f31b81968cd2247dd5e0f059e46aebb6.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/Fish_Species-1/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (4.1GB ram): 100% 3576/3576 [00:09<00:00, 396.14it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Fish_Species-1/valid/labels... 403 images, 2 backgrounds, 0 corrupt: 100% 403/403 [00:00<00:00, 511.16it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/Fish_Species-1/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.5GB ram): 100% 403/403 [00:01<00:00, 394.49it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.87 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n"
          ]
        }
      ],
      "source": [
        "!python train.py --img 640 --epochs 10 --data /content/datasets/Fish_Species-1/data.yaml  --weights yolov5l.pt --cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv3_jmXcNhuC"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy3cNritNhwa"
      },
      "outputs": [],
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 416 --conf 0.1 --source /content/datasets/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IRBQ0MMNhz0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Remplacez ce chemin par le chemin rÃ©el vers votre fichier JSON\n",
        "json_file_path = '/content/yolov5/runs/detect/exp/seabream_yolo.json'\n",
        "\n",
        "# Charger les donnÃ©es depuis le fichier JSON dans la nouvelle variable\n",
        "with open(json_file_path, 'r') as file:\n",
        "    detected_objects_yolo = json.load(file)\n",
        "# Afficher les informations des objets dÃ©tectÃ©s pour vÃ©rification, en utilisant detected_objects_yolo\n",
        "for obj in detected_objects_yolo:\n",
        "    print(f\"Classe: {obj['classe']}, Confiance: {obj['confiance']}, xmin: {obj['xmin']}, ymin: {obj['ymin']}, xmax: {obj['xmax']},  ymax: {obj['xmax']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcunKWcRNh83"
      },
      "outputs": [],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X93thSdPNh-3"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAM6OktRVlS1"
      },
      "outputs": [],
      "source": [
        "os.environ[\"DATASET_DIRECTORY\"]=\"/content/datasets2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0hGLaecUQaf"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"N0c8fvEkj4BOP2UGVqdB\")\n",
        "project = rf.workspace(\"test-gm8yy\").project(\"fish_species-sh4x2\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"coco-segmentation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzB0GkSZUQdj"
      },
      "outputs": [],
      "source": [
        "from detectron2.structures import BoxMode\n",
        "\n",
        "def get_aquarium_dicts(img_dir):\n",
        "    json_file = os.path.join(img_dir, \"_annotations.coco.json\")\n",
        "    with open(json_file) as f:\n",
        "        imgs_anns = json.load(f)\n",
        "\n",
        "    dataset_dicts = []\n",
        "    for idx, v in enumerate(imgs_anns.values()):\n",
        "        record = {}\n",
        "\n",
        "        if \"file_name\" in v:\n",
        "            filename = os.path.join(img_dir, v[\"file_name\"])\n",
        "        else:\n",
        "            # Handle the case where \"file_name\" is missing\n",
        "            continue\n",
        "\n",
        "        height, width = cv2.imread(filename).shape[:2]\n",
        "\n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "\n",
        "        annos = v[\"regions\"]\n",
        "        objs = []\n",
        "        for _, anno in annos.items():\n",
        "            assert not anno[\"region_attributes\"]\n",
        "            anno = anno[\"shape_attributes\"]\n",
        "            px = anno[\"all_points_x\"]\n",
        "            py = anno[\"all_points_y\"]\n",
        "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": 0,\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "from detectron2.data.catalog import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "# VÃ©rifiez d'abord si l'ensemble de donnÃ©es est dÃ©jÃ  enregistrÃ©\n",
        "if \"Fish_Species-1_train\" not in DatasetCatalog:\n",
        "    # Si ce n'est pas le cas, alors enregistrez-le\n",
        "    for d in [\"train\", \"valid\"]:\n",
        "        DatasetCatalog.register(\"Fish_Species-1_\" + d, lambda d=d: get_aquarium_dicts(\"/content/datasets2/Fish_Species-1/\" + d))\n",
        "        MetadataCatalog.get(\"Fish_Species-1_\" + d).set(thing_classes=[\"Fish_Species-1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZExZkgFUUQf8"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import random\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "# VÃ©rifiez si le dataset est dÃ©jÃ  enregistrÃ©, et si c'est le cas, le supprimer\n",
        "def maybe_register_dataset(name, json_file, image_root):\n",
        "    if name in DatasetCatalog:\n",
        "        DatasetCatalog.remove(name)\n",
        "    if name in MetadataCatalog:\n",
        "        MetadataCatalog.remove(name)\n",
        "    register_coco_instances(name, {}, json_file, image_root)\n",
        "\n",
        "# Noms des datasets\n",
        "dataset_name_train = \"Fish_Species-1_train\"\n",
        "dataset_name_val = \"Fish_Species-1_valid\"\n",
        "\n",
        "# Chemins vers les fichiers JSON et les images\n",
        "json_file_train = os.path.join(\"/content/datasets2/Fish_Species-1/train\", \"_annotations.coco.json\")\n",
        "json_file_val = os.path.join(\"/content/datasets2/Fish_Species-1/valid\", \"_annotations.coco.json\")\n",
        "image_root_train = \"/content/datasets2/Fish_Species-1/train\"\n",
        "image_root_val = \"/content/datasets2/Fish_Species-1/valid\"\n",
        "\n",
        "# Enregistrement des ensembles de donnÃ©es si ce n'est pas dÃ©jÃ  fait\n",
        "maybe_register_dataset(dataset_name_train, json_file_train, image_root_train)\n",
        "maybe_register_dataset(dataset_name_val, json_file_val, image_root_val)\n",
        "\n",
        "# RÃ©cupÃ©ration des mÃ©tadonnÃ©es\n",
        "metadata_train = MetadataCatalog.get(dataset_name_train)\n",
        "\n",
        "# Chargement des donnÃ©es de l'ensemble d'entraÃ®nement\n",
        "dataset_dicts = DatasetCatalog.get(dataset_name_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EiR9Cz9UQiT"
      },
      "outputs": [],
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "import os\n",
        "\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"Fish_Species-1_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 3300\n",
        "cfg.SOLVER.STEPS = []\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6\n",
        "\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRpOm2DlUQke"
      },
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQyiDMjEZPvx"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5fK-NGJZPx6"
      },
      "outputs": [],
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"Fish_Species-1_valid\", output_dir=\"./output\")\n",
        "val_loader = build_detection_test_loader(cfg, \"Fish_Species-1_valid\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.data import MetadataCatalog\n",
        "from pathlib import Path\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "\n",
        "metadata_train = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
        "images_dir = \"/content/datasets/\"\n",
        "\n",
        "\n",
        "results_dir = \"/content/Run_MaskRcnn\"\n",
        "Path(results_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "image_paths = [os.path.join(images_dir, image_name) for image_name in os.listdir(images_dir)]"
      ],
      "metadata": {
        "id": "FUs9kmTkKkLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_path in image_paths:\n",
        "    if image_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "        im = cv2.imread(image_path)\n",
        "        image_name = os.path.basename(image_path)\n",
        "        image_results_dir = os.path.join(results_dir, image_name)\n",
        "        Path(image_results_dir).mkdir(parents=True, exist_ok=True)\n",
        "        if im is None:\n",
        "            print(f\"Erreur : Impossible de charger l'image {image_name}\")\n",
        "        else:\n",
        "            outputs = predictor(im)\n",
        "            instances = outputs[\"instances\"]\n",
        "            detected_objects = []\n",
        "            for i, box in enumerate(instances.pred_boxes):\n",
        "                classe_predite = metadata_train.thing_classes[instances.pred_classes[i]] if metadata_train else \"Classe inconnue\"\n",
        "                detected_object = {\n",
        "                    \"classe\": classe_predite,\n",
        "                    \"confiance\": instances.scores[i].item(),\n",
        "                    \"xmin\": box[0].item(),\n",
        "                    \"ymin\": box[1].item(),\n",
        "                    \"xmax\": box[2].item(),\n",
        "                    \"ymax\": box[3].item()\n",
        "                }\n",
        "                if hasattr(instances, \"pred_masks\"):\n",
        "                    mask = instances.pred_masks[i].cpu().numpy()\n",
        "                    contours, _ = cv2.findContours(mask.astype('uint8'), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                    segmentation = [c.flatten().tolist() for c in contours]\n",
        "                    detected_object[\"segmentation\"] = segmentation\n",
        "                detected_objects.append(detected_object)\n",
        "            json_path = os.path.join(image_results_dir, \"detected_objects.json\")\n",
        "            with open(json_path, \"w\") as f:\n",
        "                json.dump(detected_objects, f, indent=4)\n",
        "            v = Visualizer(im[:, :, ::-1], metadata=metadata_train, scale=0.5, instance_mode=ColorMode.IMAGE_BW)\n",
        "            out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "            cv2.imwrite(os.path.join(image_results_dir, \"detection_result.jpg\"), out.get_image()[:, :, ::-1])\n",
        "            print(f\"Les objets dÃ©tectÃ©s de l'image {image_name} ont Ã©tÃ© sauvegardÃ©s dans {image_results_dir}\")"
      ],
      "metadata": {
        "id": "k8eKCYh-KoTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMPWhU3kUQoB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Remplacez ce chemin par le chemin rÃ©el vers votre fichier JSON\n",
        "json_file_path = '/content/yolov5/runs/detect/exp/seabream_yolo.json'\n",
        "\n",
        "# Charger les donnÃ©es depuis le fichier JSON dans la nouvelle variable\n",
        "with open(json_file_path, 'r') as file:\n",
        "    detected_objects_yolo = json.load(file)\n",
        "# Afficher les informations des objets dÃ©tectÃ©s pour vÃ©rification, en utilisant detected_objects_yolo\n",
        "for obj in detected_objects_yolo:\n",
        "    print(f\"Classe: {obj['classe']}, Confiance: {obj['confiance']}, xmin: {obj['xmin']}, ymin: {obj['ymin']}, xmax: {obj['xmax']},  ymax: {obj['xmax']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ienK-Z00PxQg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import cv2\n",
        "\n",
        "# DÃ©finition de la fonction pour combiner les boÃ®tes englobantes avec moyenne pondÃ©rÃ©e\n",
        "def combine_boxes_with_weighted_average(box_maskrcnn, box_yolov5, weight=0.5):\n",
        "    new_xmin = weight * box_maskrcnn['xmin'] + (1 - weight) * box_yolov5['xmin']\n",
        "    new_ymin = weight * box_maskrcnn['ymin'] + (1 - weight) * box_yolov5['ymin']\n",
        "    new_xmax = weight * box_maskrcnn['xmax'] + (1 - weight) * box_yolov5['xmax']\n",
        "    new_ymax = weight * box_maskrcnn['ymax'] + (1 - weight) * box_yolov5['ymax']\n",
        "\n",
        "    return {\n",
        "        'xmin': new_xmin,\n",
        "        'ymin': new_ymin,\n",
        "        'xmax': new_xmax,\n",
        "        'ymax': new_ymax,\n",
        "        'classe': box_maskrcnn['classe'],  # Garder la classe de Mask R-CNN\n",
        "        'confiance': (box_maskrcnn['confiance'] + box_yolov5['confiance']) / 2  # Moyenne de confiance\n",
        "    }\n",
        "\n",
        "# Liste pour stocker les nouvelles boÃ®tes englobantes combinÃ©es\n",
        "combined_boxes = []\n",
        "\n",
        "# Combiner les boÃ®tes englobantes avec moyenne pondÃ©rÃ©e\n",
        "for box_maskrcnn, box_yolov5 in zip(detected_objects_maskrcnn, detected_objects_yolov5):\n",
        "    combined_box = combine_boxes_with_weighted_average(box_maskrcnn, box_yolov5)\n",
        "    combined_boxes.append(combined_box)\n",
        "\n",
        "# Charger l'image\n",
        "image_path = \"/content/datasets/2tuna.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Dessiner les nouvelles boÃ®tes englobantes combinÃ©es sur l'image\n",
        "for box in combined_boxes:\n",
        "    xmin, ymin, xmax, ymax = map(int, [box['xmin'], box['ymin'], box['xmax'], box['ymax']])\n",
        "    cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "\n",
        "    # Afficher la classe et la confiance sur l'image\n",
        "    cv2.putText(image, f\"{box['classe']}: {box['confiance']:.2f}\", (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# Sauvegarde de l'image avec les boÃ®tes englobantes combinÃ©es\n",
        "output_image_path = \"/content/image_with_combined_boxes_weighted_average.jpeg\"\n",
        "cv2.imwrite(output_image_path, image)\n",
        "\n",
        "print(\"L'image avec les boÃ®tes englobantes combinÃ©es en utilisant la moyenne pondÃ©rÃ©e a Ã©tÃ© enregistrÃ©e avec succÃ¨s dans\", output_image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import cv2\n",
        "\n",
        "# DÃ©finition de la fonction pour combiner les boÃ®tes englobantes en utilisant IoU\n",
        "def combine_boxes_with_iou(box_maskrcnn, box_yolov5):\n",
        "    # Calculer les coordonnÃ©es de l'intersection\n",
        "    x_tl = max(box_maskrcnn['xmin'], box_yolov5['xmin'])\n",
        "    y_tl = max(box_maskrcnn['ymin'], box_yolov5['ymin'])\n",
        "    x_br = min(box_maskrcnn['xmax'], box_yolov5['xmax'])\n",
        "    y_br = min(box_maskrcnn['ymax'], box_yolov5['ymax'])\n",
        "\n",
        "    # Calculer l'aire de l'intersection\n",
        "    intersection_area = max(0, x_br - x_tl + 1) * max(0, y_br - y_tl + 1)\n",
        "\n",
        "    # Calculer l'aire des boÃ®tes englobantes individuelles\n",
        "    box_maskrcnn_area = (box_maskrcnn['xmax'] - box_maskrcnn['xmin'] + 1) * (box_maskrcnn['ymax'] - box_maskrcnn['ymin'] + 1)\n",
        "    box_yolov5_area = (box_yolov5['xmax'] - box_yolov5['xmin'] + 1) * (box_yolov5['ymax'] - box_yolov5['ymin'] + 1)\n",
        "\n",
        "    # Calculer l'union des aires des boÃ®tes englobantes\n",
        "    union_area = box_maskrcnn_area + box_yolov5_area - intersection_area\n",
        "\n",
        "    # Calculer l'Intersection over Union (IoU)\n",
        "    iou = intersection_area / union_area\n",
        "\n",
        "    # Appliquer IoU pour combiner les boÃ®tes englobantes\n",
        "    if iou > 0.5:  # Vous pouvez ajuster le seuil IoU selon vos besoins\n",
        "        # Calculer les nouvelles coordonnÃ©es en prenant la moyenne pondÃ©rÃ©e\n",
        "        new_xmin = 0.5 * (box_maskrcnn['xmin'] + box_yolov5['xmin'])\n",
        "        new_ymin = 0.5 * (box_maskrcnn['ymin'] + box_yolov5['ymin'])\n",
        "        new_xmax = 0.5 * (box_maskrcnn['xmax'] + box_yolov5['xmax'])\n",
        "        new_ymax = 0.5 * (box_maskrcnn['ymax'] + box_yolov5['ymax'])\n",
        "\n",
        "        # Garder la classe de Mask R-CNN\n",
        "        classe = box_maskrcnn['classe']\n",
        "\n",
        "        # Moyenne de confiance\n",
        "        confiance = (box_maskrcnn['confiance'] + box_yolov5['confiance']) / 2\n",
        "\n",
        "        # Retourner les nouvelles coordonnÃ©es combinÃ©es\n",
        "        return {\n",
        "            'xmin': new_xmin,\n",
        "            'ymin': new_ymin,\n",
        "            'xmax': new_xmax,\n",
        "            'ymax': new_ymax,\n",
        "            'classe': classe,\n",
        "            'confiance': confiance\n",
        "        }\n",
        "    else:\n",
        "        # Si IoU est infÃ©rieur au seuil, retourner la boÃ®te de Mask R-CNN\n",
        "        return box_maskrcnn  # Ou box_yolov5 si vous prÃ©fÃ©rez\n",
        "\n",
        "# Liste pour stocker les nouvelles boÃ®tes englobantes combinÃ©es\n",
        "combined_boxes = []\n",
        "\n",
        "# Combiner les boÃ®tes englobantes avec IoU\n",
        "for box_maskrcnn, box_yolov5 in zip(detected_objects_maskrcnn, detected_objects_yolov5):\n",
        "    combined_box = combine_boxes_with_iou(box_maskrcnn, box_yolov5)\n",
        "    combined_boxes.append(combined_box)\n",
        "\n",
        "# Charger l'image\n",
        "image_path = \"/content/datasets/2tuna.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Dessiner les nouvelles boÃ®tes englobantes combinÃ©es sur l'image\n",
        "for box in combined_boxes:\n",
        "    xmin, ymin, xmax, ymax = map(int, [box['xmin'], box['ymin'], box['xmax'], box['ymax']])\n",
        "    cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "\n",
        "    # Afficher la classe et la confiance sur l'image\n",
        "    cv2.putText(image, f\"{box['classe']}: {box['confiance']:.2f}\", (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# Sauvegarde de l'image avec les boÃ®tes englobantes combinÃ©es\n",
        "output_image_path = \"/content/image_with_combined_boxes_iou.jpeg\"\n",
        "cv2.imwrite(output_image_path, image)\n",
        "\n",
        "print(\"L'image avec les boÃ®tes englobantes combinÃ©es en utilisant IoU a Ã©tÃ© enregistrÃ©e avec succÃ¨s dans\", output_image_path)\n"
      ],
      "metadata": {
        "id": "0PS79y-RNsPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGKl13D4JEN1"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# DÃ©finition de la fonction pour combiner les boÃ®tes englobantes en utilisant IoU\n",
        "def combine_boxes_with_iou(box_maskrcnn, box_yolov5):\n",
        "    # Calculer les coordonnÃ©es de l'intersection\n",
        "    x_tl = max(box_maskrcnn['xmin'], box_yolov5['xmin'])\n",
        "    y_tl = max(box_maskrcnn['ymin'], box_yolov5['ymin'])\n",
        "    x_br = min(box_maskrcnn['xmax'], box_yolov5['xmax'])\n",
        "    y_br = min(box_maskrcnn['ymax'], box_yolov5['ymax'])\n",
        "\n",
        "    # Calculer l'aire de l'intersection\n",
        "    intersection_area = max(0, x_br - x_tl + 1) * max(0, y_br - y_tl + 1)\n",
        "\n",
        "    # Calculer l'aire des boÃ®tes englobantes individuelles\n",
        "    box_maskrcnn_area = (box_maskrcnn['xmax'] - box_maskrcnn['xmin'] + 1) * (box_maskrcnn['ymax'] - box_maskrcnn['ymin'] + 1)\n",
        "    box_yolov5_area = (box_yolov5['xmax'] - box_yolov5['xmin'] + 1) * (box_yolov5['ymax'] - box_yolov5['ymin'] + 1)\n",
        "\n",
        "    # Calculer l'union des aires des boÃ®tes englobantes\n",
        "    union_area = box_maskrcnn_area + box_yolov5_area - intersection_area\n",
        "\n",
        "    # Calculer l'Intersection over Union (IoU)\n",
        "    iou = intersection_area / union_area\n",
        "\n",
        "    # Appliquer IoU pour combiner les boÃ®tes englobantes\n",
        "    if iou > 0.5:  # Vous pouvez ajuster le seuil IoU selon vos besoins\n",
        "        # Calculer les nouvelles coordonnÃ©es en prenant la moyenne pondÃ©rÃ©e\n",
        "        new_xmin = 0.5 * (box_maskrcnn['xmin'] + box_yolov5['xmin'])\n",
        "        new_ymin = 0.5 * (box_maskrcnn['ymin'] + box_yolov5['ymin'])\n",
        "        new_xmax = 0.5 * (box_maskrcnn['xmax'] + box_yolov5['xmax'])\n",
        "        new_ymax = 0.5 * (box_maskrcnn['ymax'] + box_yolov5['ymax'])\n",
        "\n",
        "        # Garder la classe de Mask R-CNN\n",
        "        classe = box_maskrcnn['classe']\n",
        "\n",
        "        # Moyenne de confiance\n",
        "        confiance = (box_maskrcnn['confiance'] + box_yolov5['confiance']) / 2\n",
        "\n",
        "        # Retourner les nouvelles coordonnÃ©es combinÃ©es\n",
        "        return {\n",
        "            'xmin': new_xmin,\n",
        "            'ymin': new_ymin,\n",
        "            'xmax': new_xmax,\n",
        "            'ymax': new_ymax,\n",
        "            'classe': classe,\n",
        "            'confiance': confiance,\n",
        "            'segmentation': box_maskrcnn['segmentation']  # DonnÃ©es de segmentation de Mask R-CNN\n",
        "        }\n",
        "    else:\n",
        "        # Si IoU est infÃ©rieur au seuil, retourner la boÃ®te de Mask R-CNN\n",
        "        return box_maskrcnn  # Ou box_yolov5 si vous prÃ©fÃ©rez\n",
        "\n",
        "# Liste pour stocker les nouvelles boÃ®tes englobantes combinÃ©es\n",
        "combined_boxes = []\n",
        "\n",
        "# Combiner les boÃ®tes englobantes avec IoU\n",
        "for box_maskrcnn, box_yolov5 in zip(detected_objects_maskrcnn, detected_objects_yolov5):\n",
        "    combined_box = combine_boxes_with_iou(box_maskrcnn, box_yolov5)\n",
        "    combined_boxes.append(combined_box)\n",
        "\n",
        "# Charger l'image\n",
        "image_path = \"/content/datasets/2tuna.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Dessiner les nouvelles boÃ®tes englobantes combinÃ©es et les contours de segmentation\n",
        "for box in combined_boxes:\n",
        "    # Dessiner la boÃ®te englobante combinÃ©e\n",
        "    xmin, ymin, xmax, ymax = map(int, [box['xmin'], box['ymin'], box['xmax'], box['ymax']])\n",
        "    cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "    # Afficher la classe et la confiance\n",
        "    cv2.putText(image, f\"{box['classe']}: {box['confiance']:.2f}\", (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Dessiner les contours de segmentation\n",
        "    if 'segmentation' in box:\n",
        "        for segmentation in box['segmentation']:\n",
        "            points = np.array(segmentation).reshape((-1, 1, 2)).astype(np.int32)\n",
        "            cv2.drawContours(image, [points], -1, (0, 255, 255), 2)  # Dessiner le contour en jaune\n",
        "\n",
        "# Afficher l'image avec les nouvelles boÃ®tes englobantes combinÃ©es et les contours de segmentation\n",
        "cv2_imshow(image)\n",
        "\n",
        "# Sauvegarde des donnÃ©es combinÃ©es dans un fichier JSON\n",
        "output_json_path = \"/content/combined_boxes_data_iou.json\"\n",
        "with open(output_json_path, 'w') as outfile:\n",
        "    json.dump(combined_boxes, outfile, indent=4)\n",
        "\n",
        "print(\"Les donnÃ©es des boÃ®tes englobantes combinÃ©es en utilisant IoU ont Ã©tÃ© enregistrÃ©es avec succÃ¨s dans\", output_json_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE1UBXUiNU5-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Chemins vers les fichiers JSON de Mask R-CNN et de YOLOv5\n",
        "maskrcnn_json_path = \"/content/Run_MaskRcnn/2tuna.jpg/detected_objects.json\"\n",
        "yolov5_json_path = \"/content/yolov5/runs/detect/exp/2una_yolo.json\"\n",
        "\n",
        "# Charger les donnÃ©es depuis le fichier JSON de Mask R-CNN\n",
        "with open(maskrcnn_json_path, 'r') as file:\n",
        "    detected_objects_maskrcnn = json.load(file)\n",
        "\n",
        "# Charger les donnÃ©es depuis le fichier JSON de YOLOv5\n",
        "with open(yolov5_json_path, 'r') as file:\n",
        "    detected_objects_yolov5 = json.load(file)\n",
        "\n",
        "# Charger l'image\n",
        "image_path = \"/content/datasets/2tuna.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# DÃ©finition de la fonction pour combiner les boÃ®tes englobantes en utilisant IoU\n",
        "def combine_boxes_with_iou(box_maskrcnn, box_yolov5):\n",
        "    # Calculer les coordonnÃ©es de l'intersection\n",
        "    x_tl = max(box_maskrcnn['xmin'], box_yolov5['xmin'])\n",
        "    y_tl = max(box_maskrcnn['ymin'], box_yolov5['ymin'])\n",
        "    x_br = min(box_maskrcnn['xmax'], box_yolov5['xmax'])\n",
        "    y_br = min(box_maskrcnn['ymax'], box_yolov5['ymax'])\n",
        "\n",
        "    # Calculer l'aire de l'intersection\n",
        "    intersection_area = max(0, x_br - x_tl + 1) * max(0, y_br - y_tl + 1)\n",
        "\n",
        "    # Calculer l'aire des boÃ®tes englobantes individuelles\n",
        "    box_maskrcnn_area = (box_maskrcnn['xmax'] - box_maskrcnn['xmin'] + 1) * (box_maskrcnn['ymax'] - box_maskrcnn['ymin'] + 1)\n",
        "    box_yolov5_area = (box_yolov5['xmax'] - box_yolov5['xmin'] + 1) * (box_yolov5['ymax'] - box_yolov5['ymin'] + 1)\n",
        "\n",
        "    # Calculer l'union des aires des boÃ®tes englobantes\n",
        "    union_area = box_maskrcnn_area + box_yolov5_area - intersection_area\n",
        "\n",
        "    # Calculer l'Intersection over Union (IoU)\n",
        "    iou = intersection_area / union_area\n",
        "\n",
        "    # Appliquer IoU pour combiner les boÃ®tes englobantes\n",
        "    if iou > 0.5:  # Vous pouvez ajuster le seuil IoU selon vos besoins\n",
        "        # Calculer les nouvelles coordonnÃ©es en prenant la moyenne pondÃ©rÃ©e\n",
        "        new_xmin = 0.5 * (box_maskrcnn['xmin'] + box_yolov5['xmin'])\n",
        "        new_ymin = 0.5 * (box_maskrcnn['ymin'] + box_yolov5['ymin'])\n",
        "        new_xmax = 0.5 * (box_maskrcnn['xmax'] + box_yolov5['xmax'])\n",
        "        new_ymax = 0.5 * (box_maskrcnn['ymax'] + box_yolov5['ymax'])\n",
        "\n",
        "        # Garder la classe de Mask R-CNN\n",
        "        classe = box_maskrcnn['classe']\n",
        "\n",
        "        # Moyenne de confiance\n",
        "        confiance = (box_maskrcnn['confiance'] + box_yolov5['confiance']) / 2\n",
        "\n",
        "        # Retourner les nouvelles coordonnÃ©es combinÃ©es\n",
        "        return {\n",
        "            'xmin': new_xmin,\n",
        "            'ymin': new_ymin,\n",
        "            'xmax': new_xmax,\n",
        "            'ymax': new_ymax,\n",
        "            'classe': classe,\n",
        "            'confiance': confiance,\n",
        "            'segmentation': box_maskrcnn['segmentation']  # DonnÃ©es de segmentation de Mask R-CNN\n",
        "        }\n",
        "    else:\n",
        "        # Si IoU est infÃ©rieur au seuil, retourner la boÃ®te de Mask R-CNN\n",
        "        return box_maskrcnn  # Ou box_yolov5 si vous prÃ©fÃ©rez\n",
        "\n",
        "# Liste pour stocker les nouvelles boÃ®tes englobantes combinÃ©es\n",
        "combined_boxes = []\n",
        "\n",
        "# Combiner les boÃ®tes englobantes avec IoU\n",
        "for box_maskrcnn, box_yolov5 in zip(detected_objects_maskrcnn, detected_objects_yolov5):\n",
        "    combined_box = combine_boxes_with_iou(box_maskrcnn, box_yolov5)\n",
        "    combined_boxes.append(combined_box)\n",
        "\n",
        "# Dessiner les nouvelles boÃ®tes englobantes combinÃ©es et remplir les contours de segmentation avec une couleur verte transparente\n",
        "for box in combined_boxes:\n",
        "    # Dessiner la boÃ®te englobante combinÃ©e\n",
        "    xmin, ymin, xmax, ymax = map(int, [box['xmin'], box['ymin'], box['xmax'], box['ymax']])\n",
        "    cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "    # Afficher la classe et la confiance\n",
        "    cv2.putText(image, f\"{box['classe']}: {box['confiance']:.2f}\", (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # CrÃ©er un masque alpha pour la couleur verte transparente\n",
        "    alpha_mask = np.zeros_like(image)\n",
        "    if 'segmentation' in box:\n",
        "        for segmentation in box['segmentation']:\n",
        "            points = np.array(segmentation).reshape((-1, 1, 2)).astype(np.int32)\n",
        "            # Remplir le contour avec une couleur verte transparente\n",
        "            cv2.fillPoly(alpha_mask, [points], (0, 255, 0), 1)  # Couleur verte\n",
        "\n",
        "    # Fusionner le masque alpha avec l'image d'origine\n",
        "    image = cv2.addWeighted(image, 1, alpha_mask, 0.5, 0)\n",
        "\n",
        "# Afficher l'image avec les nouvelles boÃ®tes englobantes combinÃ©es et les contours de segmentation remplis avec une couleur verte transparente\n",
        "cv2_imshow(image)\n",
        "# Sauvegarde des donnÃ©es combinÃ©es dans un fichier JSON\n",
        "output_json_path = \"/content/combined_boxes_data_iou_seg.json\"\n",
        "with open(output_json_path, 'w') as outfile:\n",
        "    json.dump(combined_boxes, outfile, indent=4)\n",
        "\n",
        "print(\"Les donnÃ©es des boÃ®tes englobantes combinÃ©es en utilisant IoU ont Ã©tÃ© enregistrÃ©es avec succÃ¨s dans\", output_json_path)\n",
        "\n",
        "# Sauvegarde de l'image avec les boÃ®tes englobantes combinÃ©es\n",
        "output_image_path = \"/content/image_with_combined_boxes_iou_seg.jpeg\"\n",
        "cv2.imwrite(output_image_path, image)\n",
        "\n",
        "print(\"L'image avec les boÃ®tes englobantes combinÃ©es a Ã©tÃ© enregistrÃ©e avec succÃ¨s dans\", output_image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnZkqYnLikwU"
      },
      "outputs": [],
      "source": [
        "!python export.py --include tflite"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}